{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 딥러닝 동작원리. update rule\n",
    "1. 경사하강법. gradient decent\n",
    "2. 경사하강법 + 변수추가 --- 다중선형회귀\n",
    "3. 로지스틱 회귀. logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "by tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kitcoop\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 경사하강법\n",
    "미분한 기울기값을 비교하며 loss오차 최솟값 찾기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data= [[2,81], [4,93], [6,91], [8,97]]\n",
    "x_data= [x_row[0] for x_row in data] #요소별 앞값: 공부시간\n",
    "y_data= [y_row[1] for y_row in data] #요소별 뒷값: 시험성적 실제값"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "임의 최솟값. 기울기 a, 절편 b\n",
    "- a [0,10]\n",
    "- b [0,100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a= tf.Variable(tf.random_uniform([1], 0, 10, dtype= tf.float64, seed= 0))\n",
    "b= tf.Variable(tf.random_uniform([1], 0, 100,dtype= tf.float64, seed= 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y= ax+ b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y= a* x_data+ b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rmse= tf.sqrt(tf.reduce_mean(tf.square(y- y_data)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습률"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate= 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RMSE 최솟값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gradient_decent= tf.train.\\\n",
    "    GradientDescentOptimizer(learning_rate).minimize(rmse)\n",
    "# GradientDescentOptimizer: 경사하강법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### tf로 학습\n",
    "갈수록 RMSE가 줄어듦. a,b는 수렴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch    0.000000, RMSE 30.213942, 기울기a  7.523466, y절편b 80.598359\n",
      "epoch  100.000000, RMSE  2.886024, 기울기a  2.229946, y절편b 79.418055\n",
      "epoch  200.000000, RMSE  2.882609, 기울기a  2.260135, y절편b 79.237895\n",
      "epoch  300.000000, RMSE  2.881502, 기울기a  2.277324, y절편b 79.135320\n",
      "epoch  400.000000, RMSE  2.881143, 기울기a  2.287103, y절편b 79.076963\n",
      "epoch  500.000000, RMSE  2.881027, 기울기a  2.292665, y절편b 79.043771\n",
      "epoch  600.000000, RMSE  2.880990, 기울기a  2.295829, y절편b 79.024893\n",
      "epoch  700.000000, RMSE  2.880978, 기울기a  2.297628, y절편b 79.014157\n",
      "epoch  800.000000, RMSE  2.880974, 기울기a  2.298651, y절편b 79.008051\n",
      "epoch  900.000000, RMSE  2.880973, 기울기a  2.299233, y절편b 79.004579\n",
      "epoch 1000.000000, RMSE  2.880972, 기울기a  2.299564, y절편b 79.002604\n",
      "epoch 1100.000000, RMSE  2.880972, 기울기a  2.299752, y절편b 79.001481\n",
      "epoch 1200.000000, RMSE  2.880972, 기울기a  2.299859, y절편b 79.000842\n",
      "epoch 1300.000000, RMSE  2.880972, 기울기a  2.299920, y절편b 79.000479\n",
      "epoch 1400.000000, RMSE  2.880972, 기울기a  2.299954, y절편b 79.000272\n",
      "epoch 1500.000000, RMSE  2.880972, 기울기a  2.299974, y절편b 79.000155\n",
      "epoch 1600.000000, RMSE  2.880972, 기울기a  2.299985, y절편b 79.000088\n",
      "epoch 1700.000000, RMSE  2.880972, 기울기a  2.299992, y절편b 79.000050\n",
      "epoch 1800.000000, RMSE  2.880972, 기울기a  2.299995, y절편b 79.000028\n",
      "epoch 1900.000000, RMSE  2.880972, 기울기a  2.299997, y절편b 79.000016\n",
      "epoch 2000.000000, RMSE  2.880972, 기울기a  2.299998, y절편b 79.000009\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess: # 세션: 학습위한 자원할당\n",
    "    sess.run(tf.global_variables_initializer()) #변수 초기화\n",
    "    for step in range(2001): #2001-0+1 번 실행\n",
    "        sess.run(gradient_decent)\n",
    "        if 0== step%100: #100번째 마다 보자\n",
    "            print(\"epoch%12.6f, RMSE%10.6f, 기울기a%10.6f, y절편b%10.6f\"%\n",
    "                 (step, sess.run(rmse), sess.run(a), sess.run(b)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 경사하강법 + 변수추가\n",
    "6시간 공부하면 93점일줄 알았는데 91점. 예측값 != 실제값\n",
    "> 공부시간 외 다른 요소가 있군! 새 예측하려면 변수 개수를 늘려야 -> 다중회귀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data=[[2,0,81], [4,4,93], [6,2,91], [8,3,97]]\n",
    "x1= [x_row1[0] for x_row1 in data]\n",
    "x2= [x_row2[1] for x_row2 in data] # 변수 추가\n",
    "y_data= [y_row[2] for y_row in data] #data에서 elem하나씩 꺼내와 y_row에 넣는데, 그중 3번째 것들만"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "임의 초깃값 기울기a [0,10], 절편b [0,100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# a2: 추가 변수\n",
    "a1= tf.Variable(tf.random_uniform([1], 0,10, dtype= tf.float64, seed= 0))\n",
    "a2= tf.Variable(tf.random_uniform([1], 0,10, dtype= tf.float64, seed= 0))\n",
    "b= tf.Variable(tf.random_uniform([1], 0,100, dtype= tf.float64, seed= 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y= a1*x1 + a2*x2 + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y: 예측값, y_data: 실제값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rmse= tf.sqrt(tf.reduce_mean(tf.square( y- y_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate= 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 경사하강"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient_decent= tf.train.GradientDescentOptimizer(learning_rate).minimize(rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 학습\n",
    "100회째부터 확 수렴하는걸 보니 초깃값에 그리 큰 영향받진 X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 공부시간1개: RMSE 2.880972\n",
    "- 시간+다른변수: RMSE 1.837006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch    0.000000, RMSE 49.184210, 기울기a1  7.527029, 기울기a2  7.816014, y절편b 80.597994\n",
      "epoch  100.000000, RMSE  1.836812, 기울기a1  1.130559, 기울기a2  2.131645, y절편b 78.511887\n",
      "epoch  200.000000, RMSE  1.836972, 기울기a1  1.187870, 기울기a2  2.148749, y절편b 78.105703\n",
      "epoch  300.000000, RMSE  1.837000, 기울기a1  1.212219, 기울기a2  2.157104, y절편b 77.935173\n",
      "epoch  400.000000, RMSE  1.837005, 기울기a1  1.222564, 기울기a2  2.160666, y절편b 77.863553\n",
      "epoch  500.000000, RMSE  1.837006, 기울기a1  1.226930, 기울기a2  2.162172, y절편b 77.833469\n",
      "epoch  600.000000, RMSE  1.837006, 기울기a1  1.228768, 기울기a2  2.162807, y절편b 77.820831\n",
      "epoch  700.000000, RMSE  1.837006, 기울기a1  1.229541, 기울기a2  2.163073, y절편b 77.815522\n",
      "epoch  800.000000, RMSE  1.837006, 기울기a1  1.229866, 기울기a2  2.163186, y절편b 77.813291\n",
      "epoch  900.000000, RMSE  1.837006, 기울기a1  1.230002, 기울기a2  2.163233, y절편b 77.812354\n",
      "epoch 1000.000000, RMSE  1.837006, 기울기a1  1.230059, 기울기a2  2.163253, y절편b 77.811961\n",
      "epoch 1100.000000, RMSE  1.837006, 기울기a1  1.230083, 기울기a2  2.163261, y절편b 77.811795\n",
      "epoch 1200.000000, RMSE  1.837006, 기울기a1  1.230094, 기울기a2  2.163264, y절편b 77.811726\n",
      "epoch 1300.000000, RMSE  1.837006, 기울기a1  1.230098, 기울기a2  2.163266, y절편b 77.811697\n",
      "epoch 1400.000000, RMSE  1.837006, 기울기a1  1.230100, 기울기a2  2.163266, y절편b 77.811685\n",
      "epoch 1500.000000, RMSE  1.837006, 기울기a1  1.230100, 기울기a2  2.163267, y절편b 77.811679\n",
      "epoch 1600.000000, RMSE  1.837006, 기울기a1  1.230101, 기울기a2  2.163267, y절편b 77.811677\n",
      "epoch 1700.000000, RMSE  1.837006, 기울기a1  1.230101, 기울기a2  2.163267, y절편b 77.811676\n",
      "epoch 1800.000000, RMSE  1.837006, 기울기a1  1.230101, 기울기a2  2.163267, y절편b 77.811676\n",
      "epoch 1900.000000, RMSE  1.837006, 기울기a1  1.230101, 기울기a2  2.163267, y절편b 77.811676\n",
      "epoch 2000.000000, RMSE  1.837006, 기울기a1  1.230101, 기울기a2  2.163267, y절편b 77.811676\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as ss:\n",
    "    ss.run(tf.global_variables_initializer())\n",
    "    for step in range(2001):\n",
    "        ss.run(gradient_decent)\n",
    "        if 0== step%100:\n",
    "            print('epoch%12.6f, RMSE%10.6f, 기울기a1%10.6f, 기울기a2%10.6f, y절편b%10.6f'%\n",
    "                 (step, ss.run(rmse), ss.run(a1), ss.run(a2), ss.run(b)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 로지스틱 회귀\n",
    "- return T or F \n",
    "- param (ax + b)\n",
    "    - a 경사도. oo이면 각짐\n",
    "    - b 좌우로 이동. 크면 우측으로"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 시그모이드: 그냥한번 직접 짜봄"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data= [[2,0], [4,0], [6,0], [8,1], [10,1], [12,1], [14,1]]\n",
    "x_data= [x_row[0] for x_row in data]\n",
    "y_data= [y_row[1] for y_row in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#임의 초깃값\n",
    "a= tf.Variable(tf.random_normal([1], dtype= tf.float64, seed= 0))\n",
    "b= tf.Variable(tf.random_normal([1], dtype= tf.float64, seed= 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#날코딩\n",
    "y= 1/(1+ np.e**(a* x_data + b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 짠걸로 로지스틱 회귀 돌려봄\n",
    "결과를 0 or 1로 만들었으니 loss가 확 줄어들 수 밖에"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss= -tf.reduce_mean(np.array(y_data) * tf.log(y) + (1- np.array(y_data)) * tf.log(1-y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate= 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 경사하강. loss를 최소로하는\n",
    "gradient_decent= tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch    0.000000, loss  1.267648, 기울기a  0.184897, y절편b -0.433382\n",
      "epoch 6000.000000, loss  0.015193, 기울기a -2.921086, y절편b 20.298153\n",
      "epoch12000.000000, loss  0.008070, 기울기a -3.563739, y절편b 24.801002\n",
      "epoch18000.000000, loss  0.005475, 기울기a -3.955722, y절편b 27.546315\n",
      "epoch24000.000000, loss  0.004137, 기울기a -4.238023, y절편b 29.523131\n",
      "epoch30000.000000, loss  0.003323, 기울기a -4.458593, y절편b 31.067548\n",
      "epoch36000.000000, loss  0.002775, 기울기a -4.639561, y절편b 32.334608\n",
      "epoch42000.000000, loss  0.002382, 기울기a -4.792965, y절편b 33.408639\n",
      "epoch48000.000000, loss  0.002086, 기울기a -4.926080, y절편b 34.340596\n",
      "epoch54000.000000, loss  0.001855, 기울기a -5.043638, y절편b 35.163619\n",
      "epoch60000.000000, loss  0.001671, 기울기a -5.148889, y절편b 35.900470\n"
     ]
    }
   ],
   "source": [
    "#학습\n",
    "with tf.Session() as ss:\n",
    "    ss.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for i in range(60001):\n",
    "        ss.run(gradient_decent)\n",
    "        if 0== i%6000:\n",
    "            print('epoch%12.6f, loss%10.6f, 기울기a%10.6f, y절편b%10.6f'%\n",
    "                 (i, ss.run(loss), ss.run(a), ss.run(b)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 로지스틱회귀: 여러입력값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seed= 0\n",
    "np.random.seed(seed)\n",
    "tf.set_random_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_data= np.array([[2,3], [4,3], [6,4], [8,6], [10,7], [12,8], [14,9]])\n",
    "y_data= np.array([0, 0, 0, 1, 1, 1, 1]).reshape(7,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "입력값을 플레이스홀더에 저장\n",
    "- placeholder ??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X= tf.placeholder(tf.float64, shape= [None, 2])\n",
    "Y= tf.placeholder(tf.float64, shape= [None, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 임의 초깃값\n",
    "a= tf.Variable(tf.random_uniform([2,1], dtype= tf.float64)) #[들어오는 2개, 나가는 1개 값]\n",
    "b= tf.Variable(tf.random_uniform([1], dtype= tf.float64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "기 정의된 시그모이드 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y= tf.sigmoid(tf.matmul(X, a) + b) #matmul: 행렬곱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 오차\n",
    "loss= -tf.reduce_mean(Y* tf.log(y) + (1-Y)* tf.log(1-Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 학습률. loss줄이려고 얼마씩 이동?변경?할지\n",
    "learning_rate= 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 오차 최소. 경사하강법\n",
    "gradient_descent= tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 애매한 중간값 없이, threshold 마냥 확연한 구분!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted= tf.cast(y> 0.5, dtype= tf.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# reduce_mean: 그냥 평균인데, python 기본함수랑 구분하려고\n",
    "accuracy= tf.reduce_mean(tf.cast( tf.equal(predicted, Y),\n",
    "                                dtype= tf.float64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step  300, a1  0.924412, a2  0.163625, b  0.798926, loss       nan\n",
      "step  600, a1  0.928549, a2  0.166690, b  0.799424, loss       nan\n",
      "step  900, a1  0.932473, a2  0.169598, b  0.799897, loss       nan\n",
      "step 1200, a1  0.936206, a2  0.172364, b  0.800347, loss       nan\n",
      "step 1500, a1  0.939765, a2  0.175002, b  0.800776, loss       nan\n",
      "step 1800, a1  0.943165, a2  0.177522, b  0.801186, loss       nan\n",
      "step 2100, a1  0.946421, a2  0.179936, b  0.801579, loss       nan\n",
      "step 2400, a1  0.949544, a2  0.182252, b  0.801956, loss       nan\n",
      "step 2700, a1  0.952545, a2  0.184477, b  0.802319, loss       nan\n",
      "step 3000, a1  0.955432, a2  0.186618, b  0.802667, loss       nan\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as ss:\n",
    "    ss.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for i in range(3001):\n",
    "        a_, b_, loss_, _ = ss.run([a, b, loss, gradient_descent],\n",
    "                                 feed_dict= {X: x_data, Y: y_data})\n",
    "        if 0== (i+1)%300:\n",
    "            print('step%5d, a1%10.6f, a2%10.6f, b%10.6f, loss%10.6f'%\n",
    "                 (i+1, a_[0], a_[1], b_, loss_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
